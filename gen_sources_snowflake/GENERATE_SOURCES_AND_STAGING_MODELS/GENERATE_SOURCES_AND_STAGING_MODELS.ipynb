{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "bozqobpfqgvvttoeqyo2",
   "authorId": "196732561658",
   "authorName": "SAM_HARTING",
   "authorEmail": "sam.harting@dbtlabs.com",
   "sessionId": "b44089b7-64fb-4095-97c3-c302c6361d5c",
   "lastEditTime": 1743519914387
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Generate & write yml to a file\nimport pandas\nsession = get_active_session()\ndef generate_and_write_source_yml(schema_name, catalog, name=None):\n    \"\"\"\n    Generate a source YAML configuration.\n    \n    Args:\n        schema_name (str): The schema name\n        catalog (str): The catalog/database name\n        name (str, optional): Source name. Defaults to schema_name if not provided.\n    \n    Returns:\n        str: Generated YAML configuration as a string\n    \"\"\"\n    # Define name and tables\n    name = name or schema_name\n    get_tables_query = f\"\"\"\n    SELECT table_name FROM {catalog}.INFORMATION_SCHEMA.TABLES WHERE table_schema = '{schema}'\n    \"\"\"\n    tables = session.sql(get_tables_query).to_pandas()\n    \n    # Build starting yml\n    sources_yaml = [\n        'version: 2\\n',\n        'sources:',\n        f'  - name: {name.lower()}',\n        f'    schema: {schema_name.lower()}',\n        f'    database: {catalog.lower()}',\n        '    tables:'\n    ]\n    \n    # Add tables and their columns\n    for index, table in tables.iterrows():\n        sources_yaml.append(f'      - name: {table.iloc[0].lower()}')\n        sources_yaml.append('        columns:')\n\n        get_columns_query = f\"\"\"\n        SELECT column_name, data_type, ordinal_position FROM {catalog}.INFORMATION_SCHEMA.COLUMNS \n        WHERE table_schema = '{schema}'\n        AND table_name = '{table.iloc[0]}'\n        order by ordinal_position\n        \"\"\"\n        columns = session.sql(get_columns_query).to_pandas()\n    \n        for index, column in columns.iterrows():\n            sources_yaml.append(f'          - name: {column.iloc[0].lower()}')\n            sources_yaml.append(f'          - name: {column.iloc[1].lower()}\\n')\n    \n    # Join the list into a single string\n    yaml_output = '\\n'.join(sources_yaml)\n    yaml_path = f\"{schema_name}/_{schema_name}_sources.yml\"\n\n    # write_to_file(yaml_output, yaml_path)\n    print(yaml_output)\n    return (f\"YAML file written to: models/staging/{yaml_path}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "39f45b6e-7062-43f5-9d5f-2b174eede923",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "# Generate & write sql to a file\nimport pandas\nsession = get_active_session()\ndef generate_and_write_staging_sql(schema_name, catalog, name=None, quote_columns=False):\n    \"\"\"\n    Generate a staging SQL transformation for a table.\n    \n    Args:\n        schema_name (str): The schema name\n        catalog (str): The catalog/database name\n        name (str, optional): Source name. Defaults to schema_name if not provided.\n    \n    Returns:\n        str: Generated SQL transformation as a string\n    \"\"\"\n    # Define name and tables\n    name = name or schema_name\n    get_tables_query = f\"\"\"\n    SELECT table_name FROM {catalog}.INFORMATION_SCHEMA.TABLES WHERE table_schema = '{schema_name}'\n    \"\"\"\n    tables = session.sql(get_tables_query).to_pandas()\n\n    # Add tables and their columns\n    for index, table in tables.iterrows():\n            # Build the SQL transformation\n            staging_sql = [\n                f\"with\\n\",\n                \"source as (\\n\",\n                f\"    select * from {{{{ source('{name}', '{table.iloc[0].lower()}') }}}}\\n\",\n                \"),\\n\",\n                \"renamed as (\\n\",\n                \"    select\"\n            ]\n        \n            # Add columns with lowercase naming\n            get_columns_query = f\"\"\"\n            SELECT column_name, ordinal_position FROM {catalog}.INFORMATION_SCHEMA.COLUMNS \n            WHERE table_schema = '{schema_name}'\n            AND table_name = '{table.iloc[0]}'\n            order by ordinal_position\n            \"\"\"\n            columns = session.sql(get_columns_query).to_pandas()\n\n            for index, column in columns.iterrows():\n                if quote_columns == False:\n                    column_line = (f\"{'        ' if index == 0 else '        , '}\"\n                                f\"{column.iloc[0].lower()}\")\n                else:\n                    column_line = (f\"{'        ' if index == 0 else '        , '}\"\n                                f\"\"\" \"{column.iloc[0]}\" \"\"\")\n\n                staging_sql.append(column_line)\n        \n            # Complete the SQL transformation\n            staging_sql.extend([\n                \"\\n    from source\",\n                \"\\n)\\n\",\n                \"select * from renamed\\n\"\n            ])\n\n            # Join the list into a single string\n            sql_output = '\\n'.join(staging_sql)\n            sql_path = f\"{schema_name}/stg_{schema_name}__{table.name}.sql\"\n        \n            # write_to_file(sql_output, sql_path)\n            print(sql_output)\n            print(f\"SQL file written to: models/staging/{sql_path}\")\n\n    return (\"All sql files written successfully\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9bed4ac8-c24b-4841-87f2-560892a57890",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "# Write to file\ndef write_to_file(file_content, file_path):\n    \"\"\"\n    Write content to a file.\n    \n    Args:\n        file_content (str): content to write\n        file_path (str): Path and name of the file\n    \"\"\"\n    file_path = f\"../../models/staging/{file_path}\"\n\n    # Ensure the directory exists\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n\n    # Write to file\n    with open(file_path, 'w') as f:\n        f.write(file_content)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7947752-d43e-47a2-8b58-33ce8eb6740b",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "generate_and_write_staging_sql('DBT_SAMHARTING','DEVELOPMENT', quote_columns=True)",
   "execution_count": null
  }
 ]
}